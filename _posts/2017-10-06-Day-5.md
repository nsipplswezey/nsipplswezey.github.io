---
layout: post
title: Day 5
---

## Goal?

Build [united.vote/nyc]("https://united.vote/nyc").

What's [united.vote]("https://united.vote/")?

See [united.vote/sf]("https://united.vote/sf").

Oh [united.vote/sf]("https://united.vote/sf") is broken? They're rebuilding the new version of liquid.vote? 

And it's ![under construction](https://motherboard-images.vice.com/content-images/contentimage/26327/1444070256569233.gif)

## Day 5

Someday, day 5 will actually be Day 5. By that I mean, things take longer than you'd expect. Life pops up. The weekend comes. Starting is easy, making progress is fun, finishing is hard.

The goal of cleaning up a pull request is for the pull request to clearly solve one issue, while causing as few new other issues as possible. In essence, change the existing codebase as little as possible.

Your PR should be experienced as something like "in as few lines, of clearly readable and understandable code, that doesn't affect any other functionality of the app, I offer a solution to problem X. What do you think?" And Eric's PR is just about there.

## Changes
A lot of good things
- it's `https://united.vote` now
- purescript API has been updated, and responds with more bills per request
- schema for the API backing `united.vote/nyc` has been updated with `uid`
- `SYNC_BILLS` reducer has been fixed correctly update the `/sf` bills state
- pathing between `/sf` and `/nyc` has been narrowed down to `NextAgendaScreen`

## Next Steps
Let's make ourselves some more problems. How do we gracefully handle more local legislature APIs? What if we add `/oak` or `/santa-cruz` or `/seattle` or `/la`

I suppose the first step towards that end is to find faster ways to build and maintain them. Then address them on the client side.

Which means refactoring my scraper. Which I'm really excited about.

What's the current state, and what are the refactor goals? There's a lot to abstract.

Current state:
- single variable hard coded urls for each agenda
- seperate runs per agenda additional
- scraper doesn't check additional bills against past bills; it just adds them
- no easy way to clean wipe the `seed.json` file if needed
- deployment takes 4-5 commands
- no automation of new agendas as they are released
- query selectors have to be changed manually
- target seed has to be changed manually

Refactor goals:
- allow scraper to take an object containing urls, query selectors, target seed.json
- check additional bills against past bills before adding them
- create a wipe script to reset the production `seed.json`
- automate deploy process if possible
- test refactor on oakland city council agenda

Alright sounds good. Let's start by refactoring our NYC to accomodate these changes. Here's our first shot at an options hash for our current scraper.

```
const nycOptions = {
  agendaUrls : [
    "http://legistar.council.nyc.gov/MeetingDetail.aspx?ID=565756&GUID=2DE3E475-8E5B-4B27-9A8C-58C830156A1B",
    "http://legistar.council.nyc.gov/MeetingDetail.aspx?ID=563540&GUID=26A3BD82-86F3-47FE-A13E-AAC05219B54E" ],
  agendaDataSelectors : {
    date : "#ctl00_ContentPlaceHolder1_lblDate"
  }
  billDataSelectors : {
    bill_id: "#ctl00_ContentPlaceHolder1_lblFile2",
    item_number:"",
	title:"#ctl00_ContentPlaceHolder1_lblName2",
	text: "#ctl00_ContentPlaceHolder1_lblTitle2",
	sponsors:"#ctl00_ContentPlaceHolder1_lblSponsors2",
	fiscal_impact: "",
	status_log: "",
	question: "",
    date:  "#ctl00_ContentPlaceHolder1_lblDate",
	source_doc: "",
	uid: "", 
  },
   billDataPlaceholders : {
    bill_id: "",
    item_number:"id",
	title:"",
	text: "",
	sponsors:"",
	fiscal_impact: "None",
	status_log: [{}],
	question: "A motion was made that this Introduction be Approved by Council approved by Roll Call",
    date:  "",
	source_doc: null,
	uid: "billId", 
  } outputPaths : {
    seed : "../nyc-api/config/seed.json",
    local :  "./agenda.json"
  }		
}
```

Now I want to test this, but to do that requires either the wipe script, or checking bills from the current scrape, against past bills.












